{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Regression Project\n",
    "## Objective\n",
    "### Objective\n",
    "Use property data to predict the values of single unit properties for properties sold in May and June of 2017.\n",
    "\n",
    "Additional information we need outside of the linear model:\n",
    "\n",
    "Determine what state and county for each address\n",
    "\n",
    "\n",
    "Determine the distribution of tax rates for each county using the provided tax amount and tax value of each house.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "## Deliverables\n",
    "\n",
    "\n",
    "Your customer is the zillow data science team. State your goals as if you were delivering this to Zillow. They have asked for something from you and you are basically communicating in a more concise way, and very clearly, the goals as you understand them and as you have taken and acted upon through your research.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stakeholder and Deliverables\n",
    "Stakeholder is the zillow data science team. State goals as if this is an internal deliverable to the DS team.\n",
    "## Deliverables:\n",
    "A report (in the form of a presentation, both verbal and through a slides)\n",
    "A github repository containing your jupyter notebook that walks through the pipeline along with the .py files necessary to reproduce your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACQUIRE:\n",
    "Goal: leave this section with a dataframe ready to prepare.\n",
    "\n",
    "The ad hoc part includes summarizing your data as you read it in and begin to explore, look at the first few rows, data types, summary stats, column names, shape of the data frame, etc.\n",
    "\n",
    "acquire.py: The reproducible part is the gathering data from SQL.\n",
    "\n",
    "## NOTES:\n",
    "\n",
    "__THE IDEA OF A SINGLE FAMILY UNIT WAS A VAGUE DESCRIPTION, SO ELIMINATION OF RESIDENTIAL TYPES THAT CLEARLY DESCRIBED HOUSING UNITS THAT WOULD NOT BE CONSIDERED \"SINGLE\" WAS THE FIRST MASK IN THE QUERY. A MORE ACCURATE MODEL WOULD ENTAIL HAVING A MORE SPECIFIC DEFINITION OF SINGLE FAMILY UNIT.__\n",
    "\n",
    "__THE INSTRUCTIONS CALLED FOR A MINIMUM VIABLE PRODUCT THAT CONSIDERS THREE VARIABLES TO EXAMINE AGAINST: THE NUMBERS OF BEDROOMS, BATHROOMS, AND SQUARE FOOTAGE OF THE HOUSE COMPARED AGAINST THE ASSESSED PROPERTY VALUE FOR THE HOUSE. ADDITIONALLY, THERE IS A REQUIREMENT TO FIND AND PLOT THE DISTRIBUTION FOR THE TAX RATES FOR THE COUNTIES THE PROPERTIES RESIDE IN. AS PART OF THE SQL QUERY, TAX AMOUNT PAID WAS COMPARED AGAINST THE ASSESSED PROPERTY VALUE. FROM THERE, TABLE JOINS ELUCIDATED THE COUNTY LOCATIONS FOR THE HOUSING UNITS DERIVED FROM THE QUERY.__\n",
    "\n",
    "## YOU WILL NEED:\n",
    "\n",
    "### The acquire.py file contains the use of a personal env.py file that uses a username, password, and host to access MYSQL. You will need to create your own env.py file to allow the functions in the acquire.py file to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREP:\n",
    "## Goal: leave this section with a dataset that is ready to be analyzed. Data types are appropriate, missing values have been addressed, as have any data integrity issues.\n",
    "\n",
    "The ad hoc part includes plotting the distributions of individual variables and using those plots to identify outliers and if those should be handled (and if so, how), identify unit scales to identify how to best scale the numeric data, as well as finding erroneous or invalid data that may exist in your dataframe.\n",
    "\n",
    "Add a data dictionary in your notebook that defines all fields used in either your model or your analysis, and answers the question: why did you use the fields you used, e.g. why did you use bedroom_field1 over bedroom_field2, not why did you use number of bedrooms!\n",
    "\n",
    "## NOTE:\n",
    "\n",
    "__prep.py: The reproducible part is the handling of missing values, fixing data integrity issues, changing data types, etc. THIS PART OF THE PROCESS WAS ACCOMPLISHED IN THE ACQUIRE PHASE OF THE PROJECT. THE FUNCTIONS FOR PREP ARE FOUND IN THE acquire.py file.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT & SCALE\n",
    "\n",
    "## Goal\n",
    "\n",
    "__Leave this section with 2 dataframes (train & test) and scaled data__\n",
    "\n",
    "__split_scale.py: split data, scale data (create scaler, fit the scaler to train and transform the train and test using that scaler)__\n",
    "\n",
    "## NOTES:\n",
    "\n",
    "__To replicate accurately the data I computed, please ensure that your train/test ratio is set to .8 and the random seed is set to 123. If not, the calculations generated by a different ratio and seed will differ from my calculations__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION\n",
    "\n",
    "## Goal: \n",
    "\n",
    "__Address each of the questions you posed in your planning and brainstorming and any others you have come up with along the way through visual or statistical analysis.__\n",
    "\n",
    "## Objective\n",
    "\n",
    "__When you have completed this step, you will have the findings from your analysis that will be used in your final report, answers to specific questions your customers has asked, and information to move forward toward building a model.__\n",
    "\n",
    "__Run at least 1 t-test and 1 correlation test (but as many as you need!)__\n",
    "\n",
    "__Visualize all combinations of variables in some way(s).__\n",
    "\n",
    "__What independent variables are correlated with the dependent? (this is good)__\n",
    "\n",
    "__Which independent variables are correlated with other independent variables? (this is not so good and needs to be addressed)__\n",
    "\n",
    "## Author Thoughts:\n",
    "\n",
    "As previously discussed, the MVP variables were the number of bedrooms, number of bathrooms, and the calculated finished square feet of the house. Visualization exploration showed that there was some correlation between the independent variables, most notably between the number of bathrooms and the square footage. Intuitively, there was some correlation between the finished square footage of the house and the property value. However, the correlation is not altogether too strong, which is the same as the other variables. This suggests that the the fit of the model (r2 score) will be low. However, we'll run this model against a generic baseline (the mean of the property values) to see if there is improvement. If there is improvement, we'll continue to use this model while also examining other potential features that could produce an even better model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING & EVALUATION\n",
    "\n",
    "\n",
    "## Goal: \n",
    "\n",
    "__Develop a regression model that performs better than a baseline.__\n",
    "\n",
    "Based on the MSE and R2, the MVP model does perform better than the baseline model. However, there is much room for improvement.\n",
    "\n",
    "model.py: will have the functions to fit, predict and evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
